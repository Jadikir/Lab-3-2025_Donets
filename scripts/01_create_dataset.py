# scripts/01_create_dataset.py
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import yaml
import os
import json
from clearml import Dataset, Task
import asyncio
import httpx
from typing import Dict, List, Optional
import logging

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class WeatherDatasetCreator:
    """–°–æ–∑–¥–∞—Ç–µ–ª—å –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –≥–æ—Ä–æ–¥–æ–≤"""
    
    def __init__(self):
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–¥–∞—á–∏ ClearML
        self.task = Task.init(
            project_name='WeatherForecast',
            task_name='Multi-City Dataset Creation',
            task_type=Task.TaskTypes.data_processing
        )
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        with open('config/default.yaml', 'r') as f:
            self.config = yaml.safe_load(f)
        
        # API –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
        self.WEATHER_API_URL = "https://archive-api.open-meteo.com/v1/archive"
        
        # –ì–æ—Ä–æ–¥–∞ –¥–ª—è –¥–∞—Ç–∞—Å–µ—Ç–∞
        self.CITIES = {
            "austin": {"lat": 30.2672, "lon": -97.7431, "timezone": "America/Chicago"},
            "london": {"lat": 51.5074, "lon": -0.1278, "timezone": "Europe/London"},
            "tokyo": {"lat": 35.6762, "lon": 139.6503, "timezone": "Asia/Tokyo"},
            "sydney": {"lat": -33.8688, "lon": 151.2093, "timezone": "Australia/Sydney"}
        }
        
        # –ü—É—Ç–∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        self.dataset_dir = 'data/multi_city'
        self.models_dir = 'models/multi_city'
        
        os.makedirs(self.dataset_dir, exist_ok=True)
        os.makedirs(self.models_dir, exist_ok=True)
    
    async def fetch_city_data(self, city_name: str, city_info: Dict) -> Optional[pd.DataFrame]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–¥–Ω–æ–≥–æ –≥–æ—Ä–æ–¥–∞"""
        params = {
            "latitude": city_info["lat"],
            "longitude": city_info["lon"],
            "start_date": "2021-01-01",
            "end_date": "2023-12-31",
            "daily": "temperature_2m_max,temperature_2m_min,temperature_2m_mean,"
                     "precipitation_sum,windspeed_10m_max,weathercode",
            "timezone": city_info["timezone"],
            "format": "json"
        }
        
        try:
            async with httpx.AsyncClient(timeout=60.0) as client:
                logger.info(f"üå§Ô∏è  Fetching data for {city_name}")
                response = await client.get(self.WEATHER_API_URL, params=params)
                response.raise_for_status()
                data = response.json()
                
                if "daily" not in data:
                    return None
                
                # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ DataFrame
                df = pd.DataFrame(data["daily"])
                df = df.rename(columns={"time": "Date"})
                df["Date"] = pd.to_datetime(df["Date"])
                df["Location"] = city_name
                
                return df
                
        except Exception as e:
            logger.error(f"‚ùå Error fetching {city_name}: {e}")
            return None
    
    def create_features(self, df: pd.DataFrame, city_name: str) -> pd.DataFrame:
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –º–æ–¥–µ–ª–∏"""
        df = df.copy()
        
        # –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç–µ–æ–ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        if 'temperature_2m_mean' in df.columns:
            df['Temperature_C'] = df['temperature_2m_mean']
        
        # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (–∫–∞–∫ –≤ API)
        df['year'] = df['Date'].dt.year
        df['month'] = df['Date'].dt.month
        df['day'] = df['Date'].dt.day
        df['dayofweek'] = df['Date'].dt.dayofweek
        df['dayofyear'] = df['Date'].dt.dayofyear
        df['quarter'] = df['Date'].dt.quarter
        df['hour'] = 12
        
        # –¶–∏–∫–ª–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)
        df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)
        df['dayofyear_sin'] = np.sin(2 * np.pi * df['dayofyear'] / 365.25)
        df['dayofyear_cos'] = np.cos(2 * np.pi * df['dayofyear'] / 365.25)
        
        # –°–µ–∑–æ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        df['season'] = ((df['month'] % 12 + 3) // 3).astype(int)
        df['is_weekend'] = df['dayofweek'].isin([5, 6]).astype(int)
        
        # –õ–µ—Ç–æ/–∑–∏–º–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –ø–æ–ª—É—à–∞—Ä–∏—è
        lat = self.CITIES[city_name]["lat"]
        if lat < 0:  # –Æ–∂–Ω–æ–µ –ø–æ–ª—É—à–∞—Ä–∏–µ
            df['is_summer'] = df['month'].isin([12, 1, 2]).astype(int)
            df['is_winter'] = df['month'].isin([6, 7, 8]).astype(int)
        else:  # –°–µ–≤–µ—Ä–Ω–æ–µ –ø–æ–ª—É—à–∞—Ä–∏–µ
            df['is_summer'] = df['month'].isin([6, 7, 8]).astype(int)
            df['is_winter'] = df['month'].isin([12, 1, 2]).astype(int)
        
        # –õ–∞–≥–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        if 'Temperature_C' in df.columns:
            for lag in [1, 2, 3, 7, 14]:
                df[f'Temperature_C_lag_{lag}d'] = df['Temperature_C'].shift(lag)
        
        # –¶–µ–ª–µ–≤—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
        if 'Temperature_C' in df.columns:
            for horizon in [1, 3, 7]:
                df[f'target_temp_{horizon}d'] = df['Temperature_C'].shift(-horizon)
                df[f'target_change_{horizon}d'] = df[f'target_temp_{horizon}d'] - df['Temperature_C']
        
        return df
    
    async def create_dataset(self) -> pd.DataFrame:
        """–°–æ–∑–¥–∞–Ω–∏–µ –º—É–ª—å—Ç–∏–≥–æ—Ä–æ–¥—Å–∫–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞"""
        logger.info("=" * 70)
        logger.info("üåç –°–û–ó–î–ê–ù–ò–ï –ú–£–õ–¨–¢–ò–ì–û–†–û–î–°–ö–û–ì–û –î–ê–¢–ê–°–ï–¢–ê")
        logger.info("=" * 70)
        
        all_cities_data = []
        
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –≥–æ—Ä–æ–¥–∞
        for city_name, city_info in self.CITIES.items():
            logger.info(f"\nüìã –û–±—Ä–∞–±–æ—Ç–∫–∞ –≥–æ—Ä–æ–¥–∞: {city_name.upper()}")
            
            city_df = await self.fetch_city_data(city_name, city_info)
            if city_df is not None and len(city_df) > 0:
                city_df = self.create_features(city_df, city_name)
                all_cities_data.append(city_df)
                logger.info(f"‚úÖ {city_name}: {len(city_df)} –∑–∞–ø–∏—Å–µ–π")
            else:
                logger.error(f"‚ùå {city_name}: –ø—Ä–æ–ø—É—â–µ–Ω")
        
        if not all_cities_data:
            raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –Ω–∏ –¥–ª—è –æ–¥–Ω–æ–≥–æ –≥–æ—Ä–æ–¥–∞")
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –≥–æ—Ä–æ–¥–∞
        combined_df = pd.concat(all_cities_data, ignore_index=True)
        
        # –û—á–∏—Å—Ç–∫–∞
        initial_size = len(combined_df)
        key_cols = ['Temperature_C', 'Date']
        for horizon in ['1d', '3d', '7d']:
            if f'target_temp_{horizon}d' in combined_df.columns:
                key_cols.append(f'target_temp_{horizon}d')
        
        combined_df = combined_df.dropna(subset=key_cols)
        logger.info(f"üßπ –û—á–∏—Å—Ç–∫–∞: {initial_size - len(combined_df)} —Å—Ç—Ä–æ–∫ —É–¥–∞–ª–µ–Ω–æ")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        logger.info(f"\nüìä –ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
        logger.info(f"  ‚Ä¢ –ó–∞–ø–∏—Å–µ–π: {len(combined_df):,}")
        logger.info(f"  ‚Ä¢ –ì–æ—Ä–æ–¥–æ–≤: {len(self.CITIES)}")
        logger.info(f"  ‚Ä¢ –ü–µ—Ä–∏–æ–¥: {combined_df['Date'].min().date()} - {combined_df['Date'].max().date()}")
        
        for city in combined_df['Location'].unique():
            city_data = combined_df[combined_df['Location'] == city]
            logger.info(f"  ‚Ä¢ {city}: {len(city_data)} –¥–Ω–µ–π, "
                       f"{city_data['Temperature_C'].mean():.1f}¬∞C")
        
        return combined_df
    
    def save_dataset(self, df: pd.DataFrame):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞"""
        logger.info("\nüíæ –°–û–•–†–ê–ù–ï–ù–ò–ï –î–ê–¢–ê–°–ï–¢–ê")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç
        dataset_path = f'{self.dataset_dir}/weather_multi_city.parquet'
        df.to_parquet(dataset_path, index=False)
        logger.info(f"‚úÖ –î–∞—Ç—Å–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {dataset_path}")
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –º–æ–¥–µ–ª–∏
        exclude_cols = [
            'Date', 'Location', 
            'temperature_2m_max', 'temperature_2m_min', 'temperature_2m_mean',
            'precipitation_sum', 'windspeed_10m_max', 'weathercode',
        ]
        
        exclude_cols += [col for col in df.columns if 'target_' in col]
        
        feature_cols = [col for col in df.columns if col not in exclude_cols]
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–ø–∏—Å–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        features_path = f'{self.models_dir}/feature_list.json'
        with open(features_path, 'w') as f:
            json.dump(feature_cols, f, indent=2)
        logger.info(f"‚úÖ –°–ø–∏—Å–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {features_path}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –≥–æ—Ä–æ–¥–æ–≤
        city_metadata = {}
        for city_name, city_info in self.CITIES.items():
            city_data = df[df['Location'] == city_name]
            city_metadata[city_name] = {
                'lat': city_info["lat"],
                'lon': city_info["lon"],
                'timezone': city_info["timezone"],
                'records': int(len(city_data)),
                'temp_mean': float(city_data['Temperature_C'].mean()),
                'temp_std': float(city_data['Temperature_C'].std()),
                'temp_min': float(city_data['Temperature_C'].min()),
                'temp_max': float(city_data['Temperature_C'].max()),
                'start_date': city_data['Date'].min().strftime('%Y-%m-%d'),
                'end_date': city_data['Date'].max().strftime('%Y-%m-%d')
            }
        
        metadata_path = f'{self.dataset_dir}/city_metadata.json'
        with open(metadata_path, 'w') as f:
            json.dump(city_metadata, f, indent=2)
        logger.info(f"‚úÖ –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {metadata_path}")
        
        # –°–æ–∑–¥–∞–µ–º ClearML Dataset
        dataset = Dataset.create(
            dataset_project=self.config['project']['name'],
            dataset_name='Multi_City_Weather_v1',
            dataset_tags=['multi-city', 'api-ready', 'weather-forecast']
        )
        
        dataset.add_files(dataset_path)
        dataset.add_files(features_path)
        dataset.add_files(metadata_path)
        dataset.finalize(auto_upload=True)
        
        logger.info(f"‚úÖ ClearML Dataset —Å–æ–∑–¥–∞–Ω: {dataset.id}")
        
        # –õ–æ–≥–∏—Ä—É–µ–º –≤ ClearML
        self.task.upload_artifact('dataset_info', {
            'n_records': len(df),
            'n_cities': len(self.CITIES),
            'n_features': len(feature_cols),
            'date_range': f"{df['Date'].min().date()} - {df['Date'].max().date()}",
            'cities': list(self.CITIES.keys())
        })
        
        return dataset_path, features_path, metadata_path
    
    def run(self):
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –∑–∞–ø—É—Å–∫–∞"""
        try:
            # –°–æ–∑–¥–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç
            df = asyncio.run(self.create_dataset())
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º
            self.save_dataset(df)
            
            logger.info("\n" + "=" * 70)
            logger.info("üéâ –î–ê–¢–ê–°–ï–¢ –£–°–ü–ï–®–ù–û –°–û–ó–î–ê–ù!")
            logger.info("=" * 70)
            
            self.task.close()
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞: {e}")
            self.task.close()
            raise

if __name__ == "__main__":
    creator = WeatherDatasetCreator()
    creator.run()
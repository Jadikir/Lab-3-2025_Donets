# scripts/03_hpo_optimization.py
import pandas as pd
import numpy as np
import yaml
import os
import json
import joblib
from datetime import datetime
from clearml import Task
import optuna
import lightgbm as lgb
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import mean_absolute_error
import logging
from typing import Dict, Any

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class WeatherHPO:
    """–ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∏—á–µ—Å–∫–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è –º–æ–¥–µ–ª–∏ –ø–æ–≥–æ–¥—ã"""
    
    def __init__(self):
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–¥–∞—á–∏ ClearML
        self.task = Task.init(
            project_name='WeatherForecast',
            task_name='Multi-City HPO Optimization',
            task_type=Task.TaskTypes.optimizer
        )
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        with open('config/default.yaml', 'r') as f:
            self.config = yaml.safe_load(f)
        
        # –ü—É—Ç–∏
        self.data_dir = 'data/multi_city'
        self.models_dir = 'models/multi_city'
        self.hpo_dir = 'models/hpo'
        
        os.makedirs(self.hpo_dir, exist_ok=True)
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        self.df = pd.read_parquet(f'{self.data_dir}/weather_multi_city.parquet')
        
        with open(f'{self.models_dir}/feature_list.json', 'r') as f:
            self.features = json.load(f)
        
        # –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è
        self.target_col = 'target_temp_1d'
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        logger.info("=" * 70)
        logger.info("‚ö° –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–• –î–õ–Ø HPO")
        logger.info("=" * 70)
        
        X = self.df[self.features]
        y = self.df[self.target_col]
        
        # –û—á–∏—Å—Ç–∫–∞
        mask = y.notna() & X.notna().all(axis=1)
        self.X = X[mask]
        self.y = y[mask]
        
        logger.info(f"üìä –î–∞–Ω–Ω—ã–µ: {self.X.shape}")
        logger.info(f"üéØ –¶–µ–ª—å: {self.target_col}")
        
        # TimeSeries Split –¥–ª—è HPO
        self.tscv = TimeSeriesSplit(n_splits=3)
        logger.info(f"üîÑ TimeSeries CV: {self.tscv.n_splits} —Ñ–æ–ª–¥–∞")
    
    def objective(self, trial: optuna.Trial) -> float:
        """–¶–µ–ª–µ–≤–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"""
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        params = {
            'n_estimators': trial.suggest_int('n_estimators', 100, 1000),
            'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.3, log=True),
            'max_depth': trial.suggest_int('max_depth', 3, 12),
            'num_leaves': trial.suggest_int('num_leaves', 15, 127),
            'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),
            'subsample': trial.suggest_float('subsample', 0.5, 1.0),
            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),
            'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),
            'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),
            'min_child_weight': trial.suggest_float('min_child_weight', 1e-8, 10.0, log=True),
            'min_split_gain': trial.suggest_float('min_split_gain', 1e-8, 1.0, log=True),
            'random_state': 42,
            'n_jobs': -1,
            'verbose': -1,
            'metric': 'mae'
        }
        
        # –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è
        scores = []
        
        for fold, (train_idx, val_idx) in enumerate(self.tscv.split(self.X)):
            X_train, X_val = self.X.iloc[train_idx], self.X.iloc[val_idx]
            y_train, y_val = self.y.iloc[train_idx], self.y.iloc[val_idx]
            
            model = lgb.LGBMRegressor(**params)
            
            try:
                model.fit(
                    X_train, y_train,
                    eval_set=[(X_val, y_val)],
                    eval_metric='mae',
                    callbacks=[
                        lgb.early_stopping(stopping_rounds=30, verbose=False),
                        lgb.log_evaluation(0)
                    ]
                )
                
                y_pred = model.predict(X_val)
                mae = mean_absolute_error(y_val, y_pred)
                scores.append(mae)
                
                # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ ClearML
                self.task.get_logger().report_scalar(
                    title='Fold MAE',
                    series=f'fold_{fold}',
                    value=mae,
                    iteration=trial.number
                )
                
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ –≤ —Ñ–æ–ª–¥–µ {fold}: {e}")
                return 100.0  # –ë–æ–ª—å—à–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –∫–∞–∫ —à—Ç—Ä–∞—Ñ
        
        avg_mae = np.mean(scores)
        
        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
        self.task.get_logger().report_scalar(
            title='HPO Results',
            series='Average MAE',
            value=avg_mae,
            iteration=trial.number
        )
        
        # –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–π –≤—ã–≤–æ–¥
        if trial.number % 10 == 0:
            logger.info(f"Trial {trial.number}: MAE = {avg_mae:.4f}¬∞C")
        
        return avg_mae
    
    def run_hpo(self, n_trials: int = 50, timeout: int = 3600):
        """–ó–∞–ø—É—Å–∫ HPO"""
        logger.info("\n" + "=" * 70)
        logger.info("üöÄ –ó–ê–ü–£–°–ö HPO –° OPTUNA")
        logger.info("=" * 70)
        
        logger.info(f"‚öôÔ∏è  –ü–∞—Ä–∞–º–µ—Ç—Ä—ã HPO:")
        logger.info(f"  ‚Ä¢ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ trials: {n_trials}")
        logger.info(f"  ‚Ä¢ –¢–∞–π–º–∞—É—Ç: {timeout} —Å–µ–∫—É–Ω–¥")
        logger.info(f"  ‚Ä¢ –¶–µ–ª–µ–≤–∞—è –º–µ—Ç—Ä–∏–∫–∞: MAE (–º–∏–Ω–∏–º–∏–∑–∞—Ü–∏—è)")
        
        # –°–æ–∑–¥–∞–Ω–∏–µ study
        study_name = f'weather_hpo_{datetime.now().strftime("%Y%m%d_%H%M%S")}'
        storage_url = f'sqlite:///{self.hpo_dir}/hpo_study.db'
        
        study = optuna.create_study(
            study_name=study_name,
            direction='minimize',
            storage=storage_url,
            load_if_exists=True,
            sampler=optuna.samplers.TPESampler(seed=42)
        )
        
        logger.info(f"\nüìä Study: {study_name}")
        logger.info(f"üíæ Storage: {storage_url}")
        logger.info(f"\n‚è≥ –ù–∞—á–∞–ª–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏...")
        
        try:
            study.optimize(
                self.objective,
                n_trials=n_trials,
                timeout=timeout,
                show_progress_bar=True,
                gc_after_trial=True
            )
            
        except KeyboardInterrupt:
            logger.info("\n‚ö†Ô∏è  HPO –ø—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        except Exception as e:
            logger.error(f"\n‚ùå –û—à–∏–±–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏: {e}")
        
        return study
    
    def train_final_model(self, study: optuna.study.Study):
        """–û–±—É—á–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ –Ω–∞ –ª—É—á—à–∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–∞—Ö"""
        if not study.best_trial:
            logger.error("‚ùå –ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ HPO")
            return None
        
        logger.info("\n" + "=" * 70)
        logger.info("ü§ñ –û–ë–£–ß–ï–ù–ò–ï –§–ò–ù–ê–õ–¨–ù–û–ô –ú–û–î–ï–õ–ò")
        logger.info("=" * 70)
        
        # –õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        best_params = study.best_params.copy()
        best_params.update({
            'random_state': 42,
            'n_jobs': -1,
            'verbose': -1,
            'metric': 'mae'
        })
        
        logger.info(f"\nüèÜ –õ–£–ß–®–ò–ï –ü–ê–†–ê–ú–ï–¢–†–´:")
        for param, value in best_params.items():
            if param not in ['n_jobs', 'verbose', 'random_state', 'metric']:
                logger.info(f"  {param}: {value}")
        
        # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/test
        split_idx = int(len(self.X) * 0.8)
        X_train = self.X.iloc[:split_idx]
        X_test = self.X.iloc[split_idx:]
        y_train = self.y.iloc[:split_idx]
        y_test = self.y.iloc[split_idx:]
        
        logger.info(f"\nüìä –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö:")
        logger.info(f"  Train: {len(X_train)} –∑–∞–ø–∏—Å–µ–π")
        logger.info(f"  Test:  {len(X_test)} –∑–∞–ø–∏—Å–µ–π")
        
        # –û–±—É—á–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏
        final_model = lgb.LGBMRegressor(**best_params)
        
        logger.info("\n‚è≥ –û–±—É—á–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏...")
        final_model.fit(
            X_train, y_train,
            eval_set=[(X_test, y_test)],
            eval_metric='mae',
            callbacks=[
                lgb.early_stopping(stopping_rounds=50, verbose=True),
                lgb.log_evaluation(period=100)
            ]
        )
        
        # –û—Ü–µ–Ω–∫–∞
        y_pred_test = final_model.predict(X_test)
        test_mae = mean_absolute_error(y_test, y_pred_test)
        
        # Baseline
        baseline_mae = mean_absolute_error(
            y_test, 
            X_test['Temperature_C'] if 'Temperature_C' in X_test.columns else np.mean(y_train)
        )
        improvement = ((baseline_mae - test_mae) / baseline_mae * 100)
        
        logger.info(f"\nüìà –†–ï–ó–£–õ–¨–¢–ê–¢–´ –§–ò–ù–ê–õ–¨–ù–û–ô –ú–û–î–ï–õ–ò:")
        logger.info(f"  Test MAE:        {test_mae:.4f}¬∞C")
        logger.info(f"  Baseline MAE:    {baseline_mae:.4f}¬∞C")
        logger.info(f"  –£–ª—É—á—à–µ–Ω–∏–µ:       {improvement:.1f}%")
        logger.info(f"  –ò—Ç–µ—Ä–∞—Ü–∏–π:        {final_model.n_estimators_}")
        
        return final_model, test_mae, baseline_mae, improvement
    
    def save_results(self, study, final_model, test_mae, baseline_mae, improvement):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ HPO"""
        logger.info("\nüíæ –°–û–•–†–ê–ù–ï–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–û–í HPO")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º study
        study_path = f'{self.hpo_dir}/hpo_study.pkl'
        joblib.dump(study, study_path)
        logger.info(f"‚úÖ Study —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {study_path}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        best_params_path = f'{self.hpo_dir}/best_params.json'
        with open(best_params_path, 'w') as f:
            json.dump(study.best_params, f, indent=2)
        logger.info(f"‚úÖ –õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {best_params_path}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å
        model_data = {
            'model': final_model,
            'features': self.features,
            'target_column': self.target_col,
            'best_params': study.best_params,
            'hpo_results': {
                'best_trial': study.best_trial.number,
                'best_mae': study.best_trial.value,
                'test_mae': test_mae,
                'baseline_mae': baseline_mae,
                'improvement': improvement,
                'n_trials': len(study.trials)
            },
            'training_date': datetime.now().isoformat()
        }
        
        model_path = f'{self.hpo_dir}/hpo_optimized_model.pkl'
        joblib.dump(model_data, model_path)
        logger.info(f"‚úÖ –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å: {model_path}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        results = {
            'hpo_info': {
                'study_name': study.study_name,
                'best_trial': study.best_trial.number,
                'best_mae': float(study.best_trial.value),
                'n_trials_completed': len(study.trials),
                'duration_hours': study.best_trial.duration.total_seconds() / 3600
            },
            'model_performance': {
                'test_mae': float(test_mae),
                'baseline_mae': float(baseline_mae),
                'improvement': float(improvement)
            },
            'best_params': study.best_params,
            'features_used': len(self.features)
        }
        
        results_path = f'{self.hpo_dir}/hpo_results.json'
        with open(results_path, 'w') as f:
            json.dump(results, f, indent=2)
        logger.info(f"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã HPO: {results_path}")
        
        # –õ–æ–≥–∏—Ä—É–µ–º –≤ ClearML
        self.task.upload_artifact('best_params', study.best_params)
        self.task.upload_artifact('hpo_results', results)
        
        return model_path, results_path
    
    def create_visualizations(self, study):
        """–°–æ–∑–¥–∞–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π HPO"""
        try:
            import plotly.io as pio
            
            logger.info("\nüìä –°–û–ó–î–ê–ù–ò–ï –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–ô HPO")
            
            # 1. –ò—Å—Ç–æ—Ä–∏—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
            fig_history = optuna.visualization.plot_optimization_history(study)
            self.task.get_logger().report_plotly(
                title='Optimization History',
                series='HPO',
                figure=fig_history
            )
            
            # 2. –í–∞–∂–Ω–æ—Å—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
            fig_importance = optuna.visualization.plot_param_importances(study)
            self.task.get_logger().report_plotly(
                title='Parameter Importances',
                series='HPO',
                figure=fig_importance
            )
            
            # 3. Slice plot
            fig_slice = optuna.visualization.plot_slice(study)
            self.task.get_logger().report_plotly(
                title='Slice Plot',
                series='HPO',
                figure=fig_slice
            )
            
            logger.info("‚úÖ –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ —Å–æ–∑–¥–∞–Ω—ã –∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –≤ ClearML")
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π: {e}")
    
    def compare_with_baseline(self):
        """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª—å—é"""
        logger.info("\n" + "=" * 70)
        logger.info("üìä –°–†–ê–í–ù–ï–ù–ò–ï –° –ë–ê–ó–û–í–û–ô –ú–û–î–ï–õ–¨–Æ")
        logger.info("=" * 70)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –±–∞–∑–æ–≤—É—é –º–æ–¥–µ–ª—å
        baseline_path = f'{self.models_dir}/weather_forecast_model.pkl'
        if os.path.exists(baseline_path):
            try:
                baseline_data = joblib.load(baseline_path)
                baseline_metrics = baseline_data.get('metrics', {})
                
                if 'test' in baseline_metrics:
                    baseline_mae = baseline_metrics['test']['mae']
                    
                    logger.info(f"\nüìà –°–†–ê–í–ù–ï–ù–ò–ï:")
                    logger.info(f"  –ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å (–±–µ–∑ HPO):")
                    logger.info(f"    ‚Ä¢ Test MAE: {baseline_mae:.4f}¬∞C")
                    logger.info(f"    ‚Ä¢ Test R¬≤:  {baseline_metrics['test'].get('r2', 'N/A'):.4f}")
                    
                    # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –±—É–¥–µ—Ç –ø–æ—Å–ª–µ HPO
                    logger.info(f"\n  HPO –º–æ–¥–µ–ª—å:")
                    logger.info(f"    ‚Ä¢ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –±—É–¥—É—Ç –ø–æ—Å–ª–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏")
                    
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –±–∞–∑–æ–≤—É—é –º–æ–¥–µ–ª—å: {e}")
    
    def run(self):
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –∑–∞–ø—É—Å–∫–∞"""
        try:
            # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å baseline
            self.compare_with_baseline()
            
            # –ó–∞–ø—É—Å–∫ HPO
            study = self.run_hpo(
                n_trials=self.config.get('hpo', {}).get('n_trials', 30),
                timeout=self.config.get('hpo', {}).get('timeout', 1800)
            )
            
            if not study.best_trial:
                logger.error("‚ùå HPO –Ω–µ –¥–∞–ª–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
                self.task.close()
                return
            
            # –û–±—É—á–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏
            final_model, test_mae, baseline_mae, improvement = self.train_final_model(study)
            
            if final_model is None:
                self.task.close()
                return
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            model_path, results_path = self.save_results(
                study, final_model, test_mae, baseline_mae, improvement
            )
            
            # –°–æ–∑–¥–∞–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π
            self.create_visualizations(study)
            
            logger.info("\n" + "=" * 70)
            logger.info("üéâ HPO –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø –£–°–ü–ï–®–ù–û –ó–ê–í–ï–†–®–ï–ù–ê!")
            logger.info("=" * 70)
            
            logger.info(f"\nüìä –ò–¢–û–ì–ò:")
            logger.info(f"  ‚Ä¢ –õ—É—á—à–∏–π MAE (CV): {study.best_trial.value:.4f}¬∞C")
            logger.info(f"  ‚Ä¢ Test MAE:        {test_mae:.4f}¬∞C")
            logger.info(f"  ‚Ä¢ –£–ª—É—á—à–µ–Ω–∏–µ:       {improvement:.1f}%")
            logger.info(f"  ‚Ä¢ Trials:          {len(study.trials)}")
            
            logger.info(f"\nüíæ –°–û–•–†–ê–ù–ï–ù–ù–´–ï –§–ê–ô–õ–´:")
            logger.info(f"  ‚Ä¢ –ú–æ–¥–µ–ª—å: {model_path}")
            logger.info(f"  ‚Ä¢ –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: {self.hpo_dir}/best_params.json")
            logger.info(f"  ‚Ä¢ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã: {results_path}")
            
            self.task.close()
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ HPO: {e}")
            import traceback
            traceback.print_exc()
            self.task.close()
            raise

if __name__ == "__main__":
    hpo = WeatherHPO()
    hpo.run()